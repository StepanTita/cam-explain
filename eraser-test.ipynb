{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:50.498210Z",
     "start_time": "2024-04-11T20:29:50.495071Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('space-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:53.030369Z",
     "start_time": "2024-04-11T20:29:50.500169Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, jaccard_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from space_model.model import *\n",
    "from space_model.loss import *\n",
    "\n",
    "from logger import get_logger, log_continue\n",
    "from train import train, eval, plot_results, concept_space_to_preds\n",
    "from utils import free_resources_deco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:53.030569Z",
     "start_time": "2024-04-11T20:29:53.029305Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:53.072010Z",
     "start_time": "2024-04-11T20:29:53.029350Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:56.393047Z",
     "start_time": "2024-04-11T20:29:53.065285Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pynvml in /opt/conda/lib/python3.10/site-packages (11.5.0)\r\n"
     ]
    }
   ],
   "source": [
    "def on_gpu(f):\n",
    "    def wrapper(*args):\n",
    "        if torch.cuda.is_available():\n",
    "            return f(*args)\n",
    "        else:\n",
    "            print('cuda unavailable')\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    ! pip install pynvml\n",
    "    from pynvml import *\n",
    "\n",
    "\n",
    "@on_gpu\n",
    "def print_gpu_utilization(dev_id):\n",
    "    try:\n",
    "        nvmlInit()\n",
    "        handle = nvmlDeviceGetHandleByIndex(dev_id)\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(f\"GPU memory occupied: {info.used // 1024 ** 2} MB.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "@on_gpu\n",
    "def free_gpu_cache(dev_id=0):\n",
    "    print(\"Initial GPU Usage\")\n",
    "    print_gpu_utilization(dev_id)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    print_gpu_utilization(dev_id)\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:56.398205Z",
     "start_time": "2024-04-11T20:29:56.395858Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id = 0\n",
    "device = torch.device(f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:56.451856Z",
     "start_time": "2024-04-11T20:29:56.427063Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:56.456737Z",
     "start_time": "2024-04-11T20:29:56.428962Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-cased'\n",
    "\n",
    "DATASET_NAME = 'tdavidson/hate_speech_offensive'\n",
    "\n",
    "NUM_LABELS = 3\n",
    "N_LATENT = 128\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 16\n",
    "MAX_SEQ_LEN = 512\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_GRAD_NORM = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:58.273619Z",
     "start_time": "2024-04-11T20:29:56.431278Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['count', 'hate_speech_count', 'offensive_language_count', 'neither_count', 'class', 'tweet'],\n",
       "        num_rows: 24783\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET_NAME)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:58.274593Z",
     "start_time": "2024-04-11T20:29:58.272983Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:58.336068Z",
     "start_time": "2024-04-11T20:29:58.306661Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_preds_from_logits(outputs):\n",
    "    probs = F.softmax(outputs.logits, dim=-1).cpu()\n",
    "    pred = torch.argmax(probs, dim=-1)  # (B)\n",
    "    return outputs.loss, pred.long(), outputs.logits\n",
    "\n",
    "\n",
    "def bert_outputs_callback(outputs):\n",
    "    return F.sigmoid(outputs.hidden_states[-1].mean(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:58.346267Z",
     "start_time": "2024-04-11T20:29:58.306749Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@eval\n",
    "def eval_epoch(model, val_dataloader, config):\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    cs_val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for step, batch in enumerate(tqdm(val_dataloader, total=len(val_dataloader))):\n",
    "            ids = batch['input_ids'].to(model.device, dtype=torch.long)\n",
    "            mask = batch['attention_mask'].to(model.device, dtype=torch.long)\n",
    "            targets = batch['label'].to(model.device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)  # (B, Seq_Len, 2)\n",
    "\n",
    "            loss, pred, logits = config['preds_from_logits_func'](outputs)\n",
    "\n",
    "            val_preds += pred.detach().tolist()\n",
    "            val_labels += targets.cpu().tolist()\n",
    "\n",
    "            ### Distance Based Classification\n",
    "            # out.concept_spaces (n, B, seq_len, n_latent)\n",
    "            if hasattr(outputs, 'concept_spaces'):\n",
    "                preds = concept_space_to_preds(outputs.concept_spaces)\n",
    "\n",
    "                # multi-label classification\n",
    "                if len(targets.shape) > 1:\n",
    "                    # turn preds into one-hot\n",
    "                    preds = F.one_hot(torch.tensor(preds), len(outputs.concept_spaces))\n",
    "                cs_val_preds += preds\n",
    "            ### END\n",
    "\n",
    "            val_loss += loss.item()\n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'preds': val_preds,\n",
    "        'labels': val_labels,\n",
    "        'cs_preds': cs_val_preds,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:29:58.346388Z",
     "start_time": "2024-04-11T20:29:58.309073Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'experiment_name': 'no_rationales',\n",
    "    'log_terminal': True,\n",
    "\n",
    "    'dataset_name': DATASET_NAME,\n",
    "    'model_name': MODEL_NAME,\n",
    "\n",
    "    'num_labels': NUM_LABELS,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'iterations': 1,\n",
    "\n",
    "    'max_seq_len': MAX_SEQ_LEN,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'fp16': False,\n",
    "    'max_grad_norm': MAX_GRAD_NORM,\n",
    "    'weight_decay': 0.01,\n",
    "    'num_warmup_steps': 0,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "\n",
    "    'threshold': 0.1,\n",
    "\n",
    "    # funcs:\n",
    "    'preds_from_logits_func': get_preds_from_logits,\n",
    "    'model_outputs_callback': bert_outputs_callback,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:00.368871Z",
     "start_time": "2024-04-11T20:30:00.368663Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hatexplain-bert-base-cased-2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_name = f'hatexplain-{MODEL_NAME.replace(\"/\", \"_\")}-{NUM_EPOCHS}'\n",
    "base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:00.427294Z",
     "start_time": "2024-04-11T20:30:00.427164Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BERTOutputs:\n",
    "    def __init__(self, loss, logits, hidden_states):\n",
    "        self.loss = loss\n",
    "        self.logits = logits\n",
    "        self.hidden_states = hidden_states\n",
    "\n",
    "\n",
    "class BERTwithRationalLossForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, model, rational_weight=0.5, ce_weight=1.0):\n",
    "        super(BERTwithRationalLossForSequenceClassification, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "        self.ce_weight = ce_weight\n",
    "        self.rational_weight = rational_weight\n",
    "\n",
    "        self.classifier = torch.nn.Linear(model.config.hidden_size, model.config.num_labels)\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "        return self\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        hidden_states = outputs.hidden_states\n",
    "        last_hidden_state = hidden_states[-1]  # (B, seq_len, n_embed)\n",
    "\n",
    "        logits = self.classifier(last_hidden_state)[:, 0, :]\n",
    "\n",
    "        ce_loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        loss = self.ce_weight * ce_loss\n",
    "\n",
    "        return BERTOutputs(loss, logits, hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:09:12.028594Z",
     "start_time": "2024-04-11T20:09:09.538764Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTwithRationalLossForSequenceClassification(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(f'models/{config[\"experiment_name\"]}/{base_name}.bin')\n",
    "body_bert = AutoModel.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS, output_hidden_states=True)\n",
    "raw_model = BERTwithRationalLossForSequenceClassification(body_bert)\n",
    "raw_model.load_state_dict(state_dict)\n",
    "raw_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:09:14.648863Z",
     "start_time": "2024-04-11T20:09:14.359813Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTwithRationalLossForSequenceClassification(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:03.640422Z",
     "start_time": "2024-04-11T20:30:03.639168Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log = get_logger(f'logs/{config[\"experiment_name\"]}', base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:04.152150Z",
     "start_time": "2024-04-11T20:30:04.118173Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['count', 'hate_speech_count', 'offensive_language_count', 'neither_count', 'label', 'tweet', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 24783\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenizer(x['tweet'], truncation=True, padding='max_length', max_length=config['max_seq_len'], return_tensors='pt'),\n",
    "    batched=True\n",
    ").rename_columns({'class': 'label'})\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:05.268428Z",
     "start_time": "2024-04-11T20:30:05.268307Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(tokenized_dataset['train'], batch_size=config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:05.654894Z",
     "start_time": "2024-04-11T20:30:05.651179Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@log_continue\n",
    "def eval_results(log, results_path, model, val_dataloader, config):\n",
    "    # base_model.load_state_dict(torch.load(f'models/{config[\"dataset_name\"]}_{config[\"model_name\"]}_{config[\"num_epochs\"] * config[\"iterations\"]}.bin'))\n",
    "    # base_model.to(device)\n",
    "\n",
    "    eval_results = eval_epoch(model, val_dataloader, config)\n",
    "\n",
    "    val_loss = eval_results['loss']\n",
    "    val_preds = eval_results['preds']\n",
    "    cs_val_preds = eval_results['cs_preds']\n",
    "    val_labels = eval_results['labels']\n",
    "\n",
    "    if len(cs_val_preds) != 0:\n",
    "        cs_val_acc = accuracy_score(val_labels, cs_val_preds)\n",
    "        cs_val_f1 = f1_score(val_labels, cs_val_preds, average='macro')\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "\n",
    "    val_precision = precision_score(val_labels, val_preds, average='macro')\n",
    "\n",
    "    val_recall = recall_score(val_labels, val_preds, average='macro')\n",
    "\n",
    "    log.info(f'Val loss: {val_loss / len(val_dataloader)}')\n",
    "    log.info(f'Val acc: {val_acc}')\n",
    "\n",
    "    if len(cs_val_preds) != 0:\n",
    "        log.info(f'CS Val acc: {cs_val_acc}')\n",
    "    log.info(f'Val f1: {val_f1}')\n",
    "\n",
    "    if len(cs_val_preds) != 0:\n",
    "        log.info(f'CS Val f1: {cs_val_f1}')\n",
    "\n",
    "    log.info(f'Val precision: {val_precision}')\n",
    "    log.info(f'Val recall: {val_recall}')\n",
    "\n",
    "    if not os.path.exists(f'results/{config[\"experiment_name\"]}'):\n",
    "        os.makedirs(f'results/{config[\"experiment_name\"]}', exist_ok=True)\n",
    "\n",
    "    with open(f'results/{config[\"experiment_name\"]}/{results_path}_eval.txt', 'w') as f:\n",
    "        f.writelines(\n",
    "            [\n",
    "                f'Val loss: {val_loss / len(val_dataloader)}\\n',\n",
    "                f'Val acc: {val_acc}\\n',\n",
    "                f'CS Val acc: {cs_val_acc}\\n' if len(cs_val_preds) != 0 else 'CS Val acc: N/A\\n',\n",
    "                f'Val f1: {val_f1}\\n',\n",
    "                f'CS Val acc: {cs_val_f1}\\n' if len(cs_val_preds) != 0 else 'CS Val f1: N/A\\n',\n",
    "                f'Val precision: {val_precision}\\n',\n",
    "                f'Val recall: {val_recall}\\n'\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:13:13.255298Z",
     "start_time": "2024-04-11T20:09:25.719377Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1549/1549 [03:47<00:00,  6.81it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[36m2024-04-12 00:13:13,212 - default.terminal - INFO - Val loss: 6.449129791967595\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:13:13,213 - default.terminal - INFO - Val acc: 0.17822701045071218\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:13:13,214 - default.terminal - INFO - Val f1: 0.19654676442690336\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:13:13,214 - default.terminal - INFO - Val precision: 0.17540648957803487\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:13:13,215 - default.terminal - INFO - Val recall: 0.4102922459876579\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "eval_results(log, base_name, raw_model, test_dataloader, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:08.271860Z",
     "start_time": "2024-04-11T20:30:08.270853Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SpaceModelWithRationalLossForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_model,\n",
    "            n_embed=3,\n",
    "            n_latent=3,\n",
    "            n_concept_spaces=2,\n",
    "            l1=1e-3,\n",
    "            l2=1e-4,\n",
    "            ce_w=1.0,\n",
    "            rational_weight=0.5,\n",
    "            fine_tune=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if fine_tune:\n",
    "            for p in base_model.parameters():\n",
    "                p.requires_grad_(False)\n",
    "\n",
    "        self.device = base_model.device\n",
    "\n",
    "        self.base_model = base_model\n",
    "\n",
    "        self.space_model = SpaceModel(n_embed, n_latent, n_concept_spaces, output_concept_spaces=True)\n",
    "\n",
    "        self.classifier = torch.nn.Linear(n_concept_spaces * n_latent, n_concept_spaces)\n",
    "\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.ce_w = ce_w\n",
    "        self.rational_weight = rational_weight\n",
    "\n",
    "    def to(self, device):\n",
    "        self.device = device\n",
    "        super().to(device)\n",
    "        return self\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None, hard_rationales=None):\n",
    "        embed = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        ).last_hidden_state  # (B, max_seq_len, 768)\n",
    "\n",
    "        out = self.space_model(embed)  # SpaceModelOutput(logits=(B, n_concept_spaces * n_latent), ...)\n",
    "\n",
    "        concept_hidden = out.logits\n",
    "\n",
    "        logits = self.classifier(concept_hidden)\n",
    "\n",
    "        loss = 0.0\n",
    "        if labels is not None:\n",
    "            loss = self.ce_w * F.cross_entropy(logits, labels)\n",
    "            loss += self.l1 * losses.inter_space_loss(out.concept_spaces, labels) + \\\n",
    "                    self.l2 * losses.intra_space_loss(out.concept_spaces)\n",
    "\n",
    "        return SpaceModelForSequenceClassificationOutput(loss, logits, out.concept_spaces, out.raw_concept_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:08.795526Z",
     "start_time": "2024-04-11T20:30:08.792443Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def space_outputs_callback(outputs):\n",
    "    loss, preds, logits = get_preds_from_logits(outputs)\n",
    "    raw_concept_spaces = torch.stack(\n",
    "        [x.mean(2) for x in outputs.raw_concept_spaces]\n",
    "    ).permute(1, 0, 2)  # (B, n_concept_spaces, max_seq_len)\n",
    "    return F.sigmoid(raw_concept_spaces[torch.arange(raw_concept_spaces.size(0)), preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:09.283086Z",
     "start_time": "2024-04-11T20:30:09.075493Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'experiment_name': 'no_rationales',\n",
    "    'log_terminal': True,\n",
    "\n",
    "    'dataset_name': DATASET_NAME,\n",
    "    'model_name': MODEL_NAME,\n",
    "\n",
    "    'num_labels': NUM_LABELS,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'iterations': 1,\n",
    "\n",
    "    'max_seq_len': MAX_SEQ_LEN,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'fp16': False,\n",
    "    'max_grad_norm': MAX_GRAD_NORM,\n",
    "    'weight_decay': 0.01,\n",
    "    'num_warmup_steps': 0,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "\n",
    "    'l1': 0.1,\n",
    "    'l2': 1e-5,\n",
    "    'ce_w': 1.0,\n",
    "\n",
    "    'threshold': 0.1,\n",
    "\n",
    "    # funcs:\n",
    "    'preds_from_logits_func': get_preds_from_logits,\n",
    "    'model_outputs_callback': space_outputs_callback,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:10.895023Z",
     "start_time": "2024-04-11T20:30:10.893216Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_name = f'hatexplain_space-{MODEL_NAME.replace(\"/\", \"_\")}-({N_LATENT})_{NUM_EPOCHS}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:11.575466Z",
     "start_time": "2024-04-11T20:30:11.008363Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:13.762115Z",
     "start_time": "2024-04-11T20:30:11.613367Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpaceModelWithRationalLossForSequenceClassification(\n",
       "  (base_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (space_model): SpaceModel(\n",
       "    (concept_spaces): ModuleList(\n",
       "      (0-2): 3 x Linear(in_features=768, out_features=128, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=384, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(f'models/{config[\"experiment_name\"]}/{space_name}.bin')\n",
    "space_model = SpaceModelWithRationalLossForSequenceClassification(\n",
    "    base_model,\n",
    "    n_embed=768,\n",
    "    n_latent=N_LATENT,\n",
    "    n_concept_spaces=NUM_LABELS,\n",
    "    l1=config['l1'],\n",
    "    l2=config['l2'],\n",
    "    ce_w=config['ce_w'],\n",
    "    rational_weight=0.5,\n",
    "    fine_tune=False\n",
    ")\n",
    "space_model.load_state_dict(state_dict)\n",
    "space_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:30:13.809930Z",
     "start_time": "2024-04-11T20:30:13.761395Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpaceModelWithRationalLossForSequenceClassification(\n",
       "  (base_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (space_model): SpaceModel(\n",
       "    (concept_spaces): ModuleList(\n",
       "      (0-2): 3 x Linear(in_features=768, out_features=128, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=384, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:34:03.596435Z",
     "start_time": "2024-04-11T20:30:13.800027Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1549/1549 [03:49<00:00,  6.75it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[36m2024-04-12 00:34:03,316 - default.terminal - INFO - Val loss: 4.442464914175293\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:34:03,317 - default.terminal - INFO - Val acc: 0.17620949844651576\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:34:03,318 - default.terminal - INFO - CS Val acc: 0.1764112496469354\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:34:03,318 - default.terminal - INFO - Val f1: 0.1951944485029856\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:34:03,319 - default.terminal - INFO - CS Val f1: 0.19002573598072306\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:34:03,320 - default.terminal - INFO - Val precision: 0.15714653516595725\u001b[0m\u001b[0m\n",
      "\u001b[36m2024-04-12 00:34:03,321 - default.terminal - INFO - Val recall: 0.414399300755294\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "eval_results(log, space_name, space_model, test_dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m115"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
